---
title: "K-means clustering"
author: "Andrew Witherspoon"
date: "9/30/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The idea of K-means clustering is that we pick the centroids (an intial guess), gather the points to those centeroids, and then re-evaluate those centroids.

Requires:
*a defined distance metric
*a number of clusters
*an inital guess of the cluster centroids (often just random points)

An example:
```{r}
set.seed(1234)
par(mar=c(0,0,0,0))
x <- rnorm(12, mean=rep(1:3, each=4), sd=0.2)
y <- rnorm(12, mean=rep(c(1,2,1), each=4), sd=0.2)
plot(x,y, col="blue", pch=19, cex=2)
text(x+0.05, y+0.05, labels=as.character(1:12))
```

Use the kmeans(function)
```{r}
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame, centers = 3) #centers is number of clusters
names(kmeansObj)
kmeansObj$cluster
```
Above, we see each point is assigned to 1 of 3 clusters

We also can see the three centroids used:
```{r}
kmeansObj$centers

par(mar=rep(0,2,4))
plot(x,y, col=kmeansObj$cluster, pch = 19, cex =2) #plotting the clustered points, note that col = cluster
points(kmeansObj$centers,col=1:3,pch=3,cex =3, lwd=3) #plotting the three centroids
```

You can also visualize k-means clusters as a heatmap:
```{r}
par(mfrow = c(1,2), mar = c(2, 4, .1, .1))
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
image(t(dataMatrix)[,nrow(dataMatrix):1], yaxt = "n")
image(t(dataMatrix)[,order(kmeansObj$cluster)], yaxt = "n")
```